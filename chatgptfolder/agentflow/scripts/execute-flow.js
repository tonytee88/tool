const fs = require('fs');
const path = require('path');
const axios = require('axios');

const channelId = process.env.SLACK_CHANNEL_ID || "x"; // Capture dynamically

async function executeLLMFlow(flowData, requestType) {
    console.log("ðŸš€ Starting Flow Execution...");
  
    if (!flowData || !flowData.length) {
      console.error("âŒ No valid flowData received.");
      return;
    }
  
    const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data || flowData[0]?.flowData?.drawflow?.data;
    if (!structuredFlow || typeof structuredFlow !== "object") {
        console.error("âŒ Invalid flowData format! Expected an object but got:", structuredFlow);
        return;
    }
    
    console.log("âœ… Valid structured flow data loaded!");

    const executionId = `exec_${Date.now()}`; // ðŸŒŸ Generate unique executionId
    console.log("ðŸ”„ Generated Execution ID:", executionId); // ðŸŒŸ Debugging executionId

    const executionOrder = determineExecutionOrder(structuredFlow);
    const storedResponses = {}; // âœ… Cache responses to avoid redundant API calls
  
    for (const nodeId of executionOrder) {
      const currentNode = structuredFlow[nodeId];
  
      if (!currentNode) continue;
  
      if (currentNode.name === 'LLM Call') {
        console.log(`ðŸš€ Processing LLM Call Node: ${nodeId}`);
  
        if (storedResponses[nodeId]) {
          console.log(`âœ… Using cached response for Node ${nodeId}`);
          currentNode.data.output = storedResponses[nodeId];
        } else {
          await waitForInputs(nodeId, structuredFlow);
  
          const combinedInputs = getSortedInputs(nodeId, structuredFlow);
          console.log("ðŸ“ Combined Inputs:", combinedInputs);
  
          const selectedModel = currentNode.data.selectedModel || 'openai/gpt-4o-mini';
          console.log(`ðŸ“ Model selected for Node ${nodeId}: ${selectedModel}`);
  
          try {
            const response = await callLLMAPI(combinedInputs, selectedModel);
            const messageResponse = response.data?.completions?.[selectedModel]?.completion?.choices?.[0]?.message?.content || "âš ï¸ No valid response";
  
            console.log(`âœ… LLM Call Node (${nodeId}) Response:`, messageResponse);
  
            currentNode.data.output = messageResponse;
            storedResponses[nodeId] = messageResponse;
            updateOutputNodes(structuredFlow, nodeId, messageResponse);

        // ðŸŒŸ Store response only if it's a Browser request ðŸŒŸ
        if (requestType === "browser") {
            await axios.post('https://j7-magic-tool.vercel.app/api/agentFlowCRUD', {
            flowId: executionId, // ðŸŒŸ Unique execution ID
            nodeId, // ðŸŒŸ Output node ID
            content: messageResponse,
            timestamp: new Date().toISOString() // ðŸŒŸ Add timestamp for cleanup
            });
            console.log(`ðŸ“¤ Stored response for Execution ID: ${executionId}, Output ID: ${nodeId}`);
        } else {
          console.log(`ðŸš€ Request from Slack - Not storing response`);
        }

          } catch (error) {
            console.error(`âŒ LLM Call Node (${nodeId}) Error:`, error);
            markNodeAsError(nodeId, error.message);
          }
        }
      } else if (currentNode.name === 'Output') {
        console.log(`ðŸ“¤ Processing Output Node: ${nodeId}`);
  
        const inputConnections = currentNode.inputs.input_1?.connections?.map(conn => conn.node) || [];
        const linkedLLMNode = inputConnections.find(id => storedResponses[id]);
  
        if (linkedLLMNode) {
          const formattedResponse = formatTextAsHTML(storedResponses[linkedLLMNode]);
          currentNode.data.output = formattedResponse;
  
          console.log(`âœ… Output Node (${nodeId}) Displaying:`, formattedResponse);
          updateOutputNodes(structuredFlow, nodeId, formattedResponse);
        } else {
          console.warn(`âš ï¸ Output Node (${nodeId}) has no valid LLM input.`);
        }
      }
    }
  
    // âœ… Compile final output from all terminal nodes
    const finalOutputText = compileFinalOutputs(structuredFlow);
  
    if (finalOutputText) {
        console.log("âœ… Final Output Ready:", finalOutputText);

        // âœ… Send response to the provided callback URL (if available)
        if (callbackUrl) {
            try {
                await axios.post(callbackUrl, {
                    flowName: flowData[0].flowName,
                    response: finalOutputText
                });

                console.log(`âœ… Sent response to callback: ${callbackUrl}`);
            } catch (error) {
                console.error("âŒ Failed to send response to callback URL:", error);
            }
        }

        // âœ… Still send to Slack as before
        const filePath = generateOutputFile(finalOutputText);
        await sendSlackMessage(channelId, "âœ… Here's the final output:" + finalOutputText, filePath);
    }
  }
  

// âœ… Wait for valid input before proceeding
async function waitForInputs(nodeId, flowData) {
  return new Promise(resolve => {
    const checkInputs = () => {
      if (areInputsReady(nodeId, flowData)) {
        console.log(`âœ… Inputs for Node ${nodeId} are now ready!`);
        resolve();
      } else {
        console.log(`â³ Waiting for inputs for Node ${nodeId}...`);
        setTimeout(checkInputs, 2000);
      }
    };
    checkInputs();
  });
}

// âœ… Ensure inputs are ready before processing
function areInputsReady(nodeId, structuredFlow) {
    // âœ… Extract correct structure
    //const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data;
  
    if (!structuredFlow || !structuredFlow[nodeId]) {
      console.error(`âŒ Node ${nodeId} is missing in flowData!`);
      return false;
    }
  
    const node = structuredFlow[nodeId];
  
    const inputConnections = Object.values(node.inputs || {})
      .flatMap(input => input.connections || [])
      .map(conn => conn.node);
  
    for (const inputNodeId of inputConnections) {
      const inputNode = structuredFlow[inputNodeId];
  
      if (!inputNode) {
        console.error(`âŒ Node ${inputNodeId} is missing in flowData!`);
        return false;
      }
  
      // âœ… Read directly from the saved flowData, not the UI
      const promptData = inputNode.data?.promptText?.trim() || "";
      const outputData = inputNode.data?.output?.trim() || "";
  
      console.log(`ðŸ” Checking inputs for Node ${inputNodeId}:`);
      console.log("âœ… Output Data:", outputData);
      console.log("âœ… Prompt Data:", promptData);
  
      // ðŸš¨ Check each input node type ðŸš¨
      if (inputNode.name === "Prompt") {
        // âœ… Prompt nodes are valid if they have text
        if (!promptData) {
          console.log(`âŒ Node ${inputNodeId} is a Prompt but has no text.`);
          return false;
        }
        console.log(`âœ… Node ${inputNodeId} is a Prompt. Accepting.`);
        continue;
      } else if (inputNode.name === "LLM Call" || inputNode.name === "Output") {
        // âŒ LLM and Output nodes must have a valid output
        if (!outputData || outputData === "Waiting for response...") {
          console.log(`âŒ Node ${nodeId} is waiting for LLM/Output from Node ${inputNodeId}`);
          return false;
        }
      }
    }
  
    console.log(`âœ… Node ${nodeId} is ready for execution.`);
    return true;
  }
  
  

// âœ… Send final output to Slack
async function sendSlackMessage(channelId, message, filePath) {
  console.log(`ðŸ“© Sending message to Slack (${channelId})`);
  const slackToken = process.env.SLACK_BOT_TOKEN;

  await axios.post('https://slack.com/api/chat.postMessage', {
    channel: channelId,
    text: message
  }, {
    headers: { 'Authorization': `Bearer ${slackToken}`, 'Content-Type': 'application/json' }
  });

  console.log("âœ… Message sent to Slack.");
}

// âœ… Call LLM API
async function callLLMAPI(prompt, model) {
  try {
    const response = await axios.post('https://j7-magic-tool.vercel.app/api/agentFlowStraicoCall', {
      message: prompt,
      models: model
    });
    return response.data;
  } catch (error) {
    throw new Error(`Error calling LLM API: ${error.message}`);
  }
}

function determineExecutionOrder(structuredFlow) {
    // âœ… Extract correct data structure
    //const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data || flowData[0]?.flowData?.drawflow?.data;
    
    if (!structuredFlow) {
        console.error("âŒ Invalid flowData format from determineExecutionOrder function!");
        return [];
    }

    const executionOrder = [];
    const processedNodes = new Set();

    function traverseNode(nodeId) {
        const nodeIdStr = String(nodeId); // Ensure consistent ID format

        if (processedNodes.has(nodeIdStr)) {
            console.log(`â­ï¸ Node ${nodeIdStr} already processed.`);
            return; // âœ… Prevent duplicate visits
        }

        const node = structuredFlow[nodeIdStr];
        if (!node) return;

        console.log(`ðŸ” Analyzing Node: ${nodeIdStr} (${node.name})`);

        // Step 1: Process dependencies first (ensure inputs are processed before this node)
        const inputConnections = Object.values(node.inputs || {})
            .flatMap(input => input.connections || [])
            .map(conn => String(conn.node)) // Ensure consistency
            .filter(inputNodeId => !processedNodes.has(inputNodeId));

        inputConnections.forEach(traverseNode);

        // âœ… Only add the node once all inputs have been processed
        if (!processedNodes.has(nodeIdStr)) {
            executionOrder.push(nodeIdStr);
            processedNodes.add(nodeIdStr);
        }

        // Step 2: Process connected outputs (ensuring unique visits)
        const outputConnections = Object.values(node.outputs || {})
            .flatMap(output => output.connections || [])
            .map(conn => String(conn.node)) // Ensure consistency
            .filter(outputNodeId => !processedNodes.has(outputNodeId));

        outputConnections.forEach(traverseNode);
    }

    // Get all LLM Call nodes, sort by position, and process them **before** outputs
    const llmNodes = Object.values(structuredFlow)
        .filter(node => node.name === 'LLM Call')
        .sort((a, b) => (a.pos_y === b.pos_y ? a.pos_x - b.pos_x : a.pos_y - b.pos_y));

    llmNodes.forEach(llmNode => traverseNode(llmNode.id));

    console.log("âœ… Final executionOrder:", executionOrder);
    return executionOrder;
}

  
function getSortedInputs(nodeId, structuredFlow) {
    // âœ… Extract correct data structure
    //const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data;

    if (!structuredFlow || !structuredFlow[nodeId]) {
        console.error(`âŒ Node ${nodeId} not found in flowData!`);
        return "";
    }

    const node = structuredFlow[nodeId];
    console.log("Processing Node ID:", nodeId);

    const inputConnections = node.inputs?.input_1?.connections || [];

    if (inputConnections.length === 0) {
        // âœ… Read from stored flowData instead of the browser DOM
        return node.data?.promptText?.trim() || "";
    }

    // âœ… Gather all connected input nodes and read from `flowData`
    const connectedNodes = inputConnections.map(conn => {
        const connectedNodeId = conn.node;
        const connectedNode = structuredFlow[connectedNodeId];

        if (!connectedNode) {
            console.warn(`âš ï¸ Connected Node ${connectedNodeId} is missing!`);
            return null;
        }

        //console.log(`ðŸ” Inspecting Node ${connectedNodeId}:`, connectedNode.data); // Debugging
        let connectedText = "";

        // âœ… Read directly from the saved flowData instead of querying the DOM
        if (connectedNode.name === "Prompt") {
            connectedText = connectedNode.data?.promptText?.trim() || "";
            //console.log(`âœ… Extracted Prompt Text: "${connectedText}" from Node ${connectedNodeId}`);
        } else if (connectedNode.name === "Output") {
            connectedText = connectedNode.data?.output?.trim() || "";
        } else if (connectedNode.name === "LLM Call") {
            connectedText = connectedNode.data?.output?.trim() || "";
        }

        return {
            id: connectedNodeId,
            x: connectedNode.pos_x,
            y: connectedNode.pos_y,
            text: connectedText,
        };
    }).filter(Boolean);

    // âœ… Sort inputs left to right, top to bottom
    connectedNodes.sort((a, b) => (a.y === b.y ? a.x - b.x : a.y - b.y));

    // âœ… Combine all inputs into one string
    return connectedNodes.map(node => node.text).join(" and ");
}


function formatTextAsHTML(text) {
if (!text) return ""; // Prevent errors with empty text

// âœ… Preserve line breaks
let formattedText = text.replace(/\n/g, "<br>");

// âœ… Convert markdown-like bold text (**bold**) to HTML <strong>
formattedText = formattedText.replace(/\*\*(.*?)\*\*/g, "<strong>$1</strong>");

// âœ… Convert markdown-style headings (### Title) into <h3>
formattedText = formattedText.replace(/### (.*?)<br>/g, "<h3>$1</h3>");

// âœ… Convert horizontal separators (---) into <hr>
formattedText = formattedText.replace(/---/g, "<hr>");

return formattedText;
}

function updateOutputNodes(structuredFlow, nodeId, responseText) {
    // âœ… Extract the actual flowData from the array
    //const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data;
  
    if (!structuredFlow || !structuredFlow[nodeId]) {
      console.error(`âŒ Node ${nodeId} not found in flowData`);
      return;
    }
  
    // âœ… Update output in the object-based flowData
    structuredFlow[nodeId].data.output = responseText;
  
    console.log(`âœ… Updated output for Node ${nodeId}:`, responseText);
  }
    
function markNodeAsError(flowData, nodeId, errorMessage) {
if (!flowData[nodeId]) {
    console.error(`âŒ Node ${nodeId} not found in flowData`);
    return;
}

// âœ… Store the error message in `flowData`
flowData[nodeId].data.error = errorMessage;

console.warn(`âš ï¸ Marked Node ${nodeId} as error: ${errorMessage}`);
}
  
function compileFinalOutputs(flowData) {
    //console.log("ðŸ” Now running the final outputs compiler function...");
    
    const allNodes = flowData;
    let finalOutputText = "";
  
    Object.values(allNodes).forEach(node => {
      if (node.name === "Output") {
        //console.log(`ðŸ›  Found Output Node: ${node.id}, checking connections...`);
        //console.log(`ðŸ”— Output connections:`, node.outputs);
  
        // âœ… Check if there are NO output connections at all
        const hasConnections = node.outputs && Object.keys(node.outputs).some(key => node.outputs[key].connections.length > 0);
  
        if (!hasConnections) {
          //console.log(`ðŸ“Œ Final Output Node Detected: ${node.id}`);
          finalOutputText += `${node.data.output || "No output generated"}\n\n`;
        }
      }
    });
  
    console.log("âœ… Final Output Compilation Complete:", finalOutputText.trim());
    return finalOutputText.trim();
  }
  

function generateOutputFile(outputText) {
  const filePath = path.join('/tmp', 'final_output.txt');
  fs.writeFileSync(filePath, outputText, 'utf8');
  console.log('âœ… Final Output File Created:', filePath);
  return filePath;
}


// âœ… Export function
module.exports = executeLLMFlow;

const fs = require('fs');
const path = require('path');
const axios = require('axios');

const channelId = process.env.SLACK_CHANNEL_ID || "x"; // Capture dynamically

async function executeLLMFlow(flowData) {
    console.log("ðŸš€ Starting Flow Execution...");
  
    if (!flowData || !flowData.length) {
      console.error("âŒ No valid flowData received.");
      return;
    }
  
    // âœ… Extract proper flow data structure
    const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data || flowData[0]?.flowData?.drawflow?.data;
    console.log("structuredflow data: ", JSON.stringify(structuredFlow, null, 2));
    if (!structuredFlow || typeof structuredFlow !== "object") {
        console.error("âŒ Invalid flowData format! Expected an object but got:", structuredFlow);
        return;
    }
    
    console.log("âœ… Valid structured flow data loaded!");
  
    const executionOrder = determineExecutionOrder(structuredFlow);
    const storedResponses = {}; // âœ… Cache responses to avoid redundant API calls
  
    for (const nodeId of executionOrder) {
      const currentNode = structuredFlow[nodeId];
  
      if (!currentNode) continue;
  
      if (currentNode.name === 'LLM Call') {
        console.log(`ðŸš€ Processing LLM Call Node: ${nodeId}`);
  
        if (storedResponses[nodeId]) {
          console.log(`âœ… Using cached response for Node ${nodeId}`);
          currentNode.data.output = storedResponses[nodeId];
        } else {
          await waitForInputs(nodeId, structuredFlow);
  
          const combinedInputs = getSortedInputs(nodeId, structuredFlow);
          console.log("ðŸ“ Combined Inputs:", combinedInputs);
  
          const selectedModel = currentNode.data.selectedModel || 'openai/gpt-4o-mini';
          console.log(`ðŸ“ Model selected for Node ${nodeId}: ${selectedModel}`);
  
          try {
            const response = await callLLMAPI(combinedInputs, selectedModel);
            const messageResponse = response.data?.completions?.[selectedModel]?.completion?.choices?.[0]?.message?.content || "âš ï¸ No valid response";
  
            console.log(`âœ… LLM Call Node (${nodeId}) Response:`, messageResponse);
  
            currentNode.data.output = messageResponse;
            storedResponses[nodeId] = messageResponse;
            updateOutputNodes(structuredFlow, nodeId, messageResponse);
          } catch (error) {
            console.error(`âŒ LLM Call Node (${nodeId}) Error:`, error);
            markNodeAsError(nodeId, error.message);
          }
        }
      } else if (currentNode.name === 'Output') {
        console.log(`ðŸ“¤ Processing Output Node: ${nodeId}`);
  
        const inputConnections = currentNode.inputs.input_1?.connections?.map(conn => conn.node) || [];
        const linkedLLMNode = inputConnections.find(id => storedResponses[id]);
  
        if (linkedLLMNode) {
          const formattedResponse = formatTextAsHTML(storedResponses[linkedLLMNode]);
          currentNode.data.output = formattedResponse;
  
          console.log(`âœ… Output Node (${nodeId}) Displaying:`, formattedResponse);
          updateOutputNodes(structuredFlow, nodeId, formattedResponse);
        } else {
          console.warn(`âš ï¸ Output Node (${nodeId}) has no valid LLM input.`);
        }
      }
    }
  
    // âœ… Compile final output from all terminal nodes
    const finalOutputText = compileFinalOutputs(structuredFlow);
  
    if (finalOutputText) {
      console.log("llm response output combined: " + finalOutputText)
      const filePath = generateOutputFile(finalOutputText);
      await sendSlackMessage(channelId, "âœ… Here's the final output:" + finalOutputText, filePath);
      await sendSlackMessage(channelId, "âœ… Here's the final output:", filePath);
    }
  }
  

// âœ… Wait for valid input before proceeding
async function waitForInputs(nodeId, flowData) {
  return new Promise(resolve => {
    const checkInputs = () => {
      if (areInputsReady(nodeId, flowData)) {
        console.log(`âœ… Inputs for Node ${nodeId} are now ready!`);
        resolve();
      } else {
        console.log(`â³ Waiting for inputs for Node ${nodeId}...`);
        setTimeout(checkInputs, 2000);
      }
    };
    checkInputs();
  });
}

// âœ… Ensure inputs are ready before processing
function areInputsReady(nodeId, flowData) {
    // âœ… Extract correct structure
    const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data;
  
    if (!structuredFlow || !structuredFlow[nodeId]) {
      console.error(`âŒ Node ${nodeId} is missing in flowData!`);
      return false;
    }
  
    const node = structuredFlow[nodeId];
  
    const inputConnections = Object.values(node.inputs || {})
      .flatMap(input => input.connections || [])
      .map(conn => conn.node);
  
    for (const inputNodeId of inputConnections) {
      const inputNode = structuredFlow[inputNodeId];
  
      if (!inputNode) {
        console.error(`âŒ Node ${inputNodeId} is missing in flowData!`);
        return false;
      }
  
      // âœ… Read directly from the saved flowData, not the UI
      const promptData = inputNode.data?.promptText?.trim() || "";
      const outputData = inputNode.data?.output?.trim() || "";
  
      console.log(`ðŸ” Checking inputs for Node ${inputNodeId}:`);
      console.log("âœ… Output Data:", outputData);
      console.log("âœ… Prompt Data:", promptData);
  
      // ðŸš¨ Check each input node type ðŸš¨
      if (inputNode.name === "Prompt") {
        // âœ… Prompt nodes are valid if they have text
        if (!promptData) {
          console.log(`âŒ Node ${inputNodeId} is a Prompt but has no text.`);
          return false;
        }
        console.log(`âœ… Node ${inputNodeId} is a Prompt. Accepting.`);
        continue;
      } else if (inputNode.name === "LLM Call" || inputNode.name === "Output") {
        // âŒ LLM and Output nodes must have a valid output
        if (!outputData || outputData === "Waiting for response...") {
          console.log(`âŒ Node ${nodeId} is waiting for LLM/Output from Node ${inputNodeId}`);
          return false;
        }
      }
    }
  
    console.log(`âœ… Node ${nodeId} is ready for execution.`);
    return true;
  }
  
  

// âœ… Send final output to Slack
async function sendSlackMessage(channelId, message, filePath) {
  console.log(`ðŸ“© Sending message to Slack (${channelId})`);
  const slackToken = process.env.SLACK_BOT_TOKEN;

  await axios.post('https://slack.com/api/chat.postMessage', {
    channel: channelId,
    text: message
  }, {
    headers: { 'Authorization': `Bearer ${slackToken}`, 'Content-Type': 'application/json' }
  });

  console.log("âœ… Message sent to Slack.");
}

// âœ… Call LLM API
async function callLLMAPI(prompt, model) {
  try {
    const response = await axios.post('https://j7-magic-tool.vercel.app/api/agentFlowStraicoCall', {
      message: prompt,
      models: model
    });
    return response.data;
  } catch (error) {
    throw new Error(`Error calling LLM API: ${error.message}`);
  }
}

function determineExecutionOrder(flowData) {
    // âœ… Extract correct data structure
    const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data;
    
    if (!structuredFlow) {
        console.error("âŒ Invalid flowData format from determineExecutionOrder function!");
        return [];
    }

    const executionOrder = [];
    const processedNodes = new Set();

    function traverseNode(nodeId) {
        const nodeIdStr = String(nodeId); // Ensure consistent ID format

        if (processedNodes.has(nodeIdStr)) {
            console.log(`â­ï¸ Node ${nodeIdStr} already processed.`);
            return; // âœ… Prevent duplicate visits
        }

        const node = structuredFlow[nodeIdStr];
        if (!node) return;

        console.log(`ðŸ” Analyzing Node: ${nodeIdStr} (${node.name})`);

        // Step 1: Process dependencies first (ensure inputs are processed before this node)
        const inputConnections = Object.values(node.inputs || {})
            .flatMap(input => input.connections || [])
            .map(conn => String(conn.node)) // Ensure consistency
            .filter(inputNodeId => !processedNodes.has(inputNodeId));

        inputConnections.forEach(traverseNode);

        // âœ… Only add the node once all inputs have been processed
        if (!processedNodes.has(nodeIdStr)) {
            executionOrder.push(nodeIdStr);
            processedNodes.add(nodeIdStr);
        }

        // Step 2: Process connected outputs (ensuring unique visits)
        const outputConnections = Object.values(node.outputs || {})
            .flatMap(output => output.connections || [])
            .map(conn => String(conn.node)) // Ensure consistency
            .filter(outputNodeId => !processedNodes.has(outputNodeId));

        outputConnections.forEach(traverseNode);
    }

    // Get all LLM Call nodes, sort by position, and process them **before** outputs
    const llmNodes = Object.values(structuredFlow)
        .filter(node => node.name === 'LLM Call')
        .sort((a, b) => (a.pos_y === b.pos_y ? a.pos_x - b.pos_x : a.pos_y - b.pos_y));

    llmNodes.forEach(llmNode => traverseNode(llmNode.id));

    console.log("âœ… Final executionOrder:", executionOrder);
    return executionOrder;
}

  
function getSortedInputs(nodeId, flowData) {
    // âœ… Extract correct data structure
    const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data;

    if (!structuredFlow || !structuredFlow[nodeId]) {
        console.error(`âŒ Node ${nodeId} not found in flowData!`);
        return "";
    }

    const node = structuredFlow[nodeId];
    console.log("Processing Node ID:", nodeId);

    const inputConnections = node.inputs?.input_1?.connections || [];

    if (inputConnections.length === 0) {
        // âœ… Read from stored flowData instead of the browser DOM
        return node.data?.promptText?.trim() || "";
    }

    // âœ… Gather all connected input nodes and read from `flowData`
    const connectedNodes = inputConnections.map(conn => {
        const connectedNodeId = conn.node;
        const connectedNode = structuredFlow[connectedNodeId];

        if (!connectedNode) {
            console.warn(`âš ï¸ Connected Node ${connectedNodeId} is missing!`);
            return null;
        }

        let connectedText = "";

        // âœ… Read directly from the saved flowData instead of querying the DOM
        if (connectedNode.name === "Prompt") {
            connectedText = connectedNode.data?.promptText?.trim() || "";
        } else if (connectedNode.name === "Output") {
            connectedText = connectedNode.data?.output?.trim() || "";
        } else if (connectedNode.name === "LLM Call") {
            connectedText = connectedNode.data?.output?.trim() || "";
        }

        return {
            id: connectedNodeId,
            x: connectedNode.pos_x,
            y: connectedNode.pos_y,
            text: connectedText,
        };
    }).filter(Boolean);

    // âœ… Sort inputs left to right, top to bottom
    connectedNodes.sort((a, b) => (a.y === b.y ? a.x - b.x : a.y - b.y));

    // âœ… Combine all inputs into one string
    return connectedNodes.map(node => node.text).join(" and ");
}


function formatTextAsHTML(text) {
if (!text) return ""; // Prevent errors with empty text

// âœ… Preserve line breaks
let formattedText = text.replace(/\n/g, "<br>");

// âœ… Convert markdown-like bold text (**bold**) to HTML <strong>
formattedText = formattedText.replace(/\*\*(.*?)\*\*/g, "<strong>$1</strong>");

// âœ… Convert markdown-style headings (### Title) into <h3>
formattedText = formattedText.replace(/### (.*?)<br>/g, "<h3>$1</h3>");

// âœ… Convert horizontal separators (---) into <hr>
formattedText = formattedText.replace(/---/g, "<hr>");

return formattedText;
}

function updateOutputNodes(flowData, nodeId, responseText) {
    // âœ… Extract the actual flowData from the array
    const structuredFlow = flowData[0]?.flowData?.drawflow?.Home?.data;
  
    if (!structuredFlow || !structuredFlow[nodeId]) {
      console.error(`âŒ Node ${nodeId} not found in flowData`);
      return;
    }
  
    // âœ… Update output in the object-based flowData
    structuredFlow[nodeId].data.output = responseText;
  
    console.log(`âœ… Updated output for Node ${nodeId}:`, responseText);
  }
    
function markNodeAsError(flowData, nodeId, errorMessage) {
if (!flowData[nodeId]) {
    console.error(`âŒ Node ${nodeId} not found in flowData`);
    return;
}

// âœ… Store the error message in `flowData`
flowData[nodeId].data.error = errorMessage;

console.warn(`âš ï¸ Marked Node ${nodeId} as error: ${errorMessage}`);
}
  
function compileFinalOutputs(flowData) {
const allNodes = flowData;
let finalOutputText = "";

Object.values(allNodes).forEach(node => {
    if (node.name === "Output" && (!node.outputs || Object.keys(node.outputs).length === 0)) {
    console.log(`ðŸ“Œ Final Output Node Detected: ${node.id}`);
    finalOutputText += `${node.data.output || "No output generated"}\n\n`;
    }
});

return finalOutputText.trim();
}

function generateOutputFile(outputText) {
  const filePath = path.join('/tmp', 'final_output.txt');
  fs.writeFileSync(filePath, outputText, 'utf8');
  console.log('âœ… Final Output File Created:', filePath);
  return filePath;
}


// âœ… Export function
module.exports = executeLLMFlow;
